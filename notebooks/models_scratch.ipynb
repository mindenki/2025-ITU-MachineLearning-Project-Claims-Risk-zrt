{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gonna run our scratch models here, hypertune them, evaluate them and save the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os \n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV   \n",
    "\n",
    "# importing custom modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from src.data.load_data import load_data\n",
    "\n",
    "from src.models.MLP_scratch import MLP as MLP_scratch, Trainer as Trainer_scratch\n",
    "from src.models.tuning import run_random_search\n",
    "# from src.utils.optimiziers import Adam, SGD, SGDMomentum, Adagrad\n",
    "# from src.utils.losses import MAE, MSE, Huber, LogCosh\n",
    "from src.visualization.model_plots import prediction_distribution, parity_plot, residual_plot,  plot_learning_curve\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the `X` features and the specified `y` targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"log_ClaimRate\"\n",
    "\n",
    "(X_train, y_train), (X_test, y_test)= load_data(raw=False, target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make an instance of our Neural Network class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = Trainer_scratch(input_dim=X_train.shape[1], \n",
    "                      hidden_sizes=[32, 64],\n",
    "                      model=MLP_scratch,\n",
    "                      optimizer=\"adam\",\n",
    "                      loss_fn=\"mse\",\n",
    "                      epochs=100\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we also need to define our parameter distributions for RandomizedGridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_MLP = {\n",
    "    \"hidden_sizes\": [\n",
    "        [32, 64], \n",
    "        [64, 128], \n",
    "        [128, 256],\n",
    "        [32, 64, 128],\n",
    "        [64, 128, 256],\n",
    "        [8, 16, 32, 64],\n",
    "        [16, 32, 64, 128],\n",
    "    ],\n",
    "    \"optimizer\": [\"sgd\", \"sgd_momentum\", \"adam\", \"adagrad\"],\n",
    "    \"loss_fn\": [\"mse\", \"mae\", \"huber\", \"logcosh\"],\n",
    "    \"batch_size\": [32, 64, 128, 256],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() missing 4 required positional arguments: 'input_dim', 'hidden_sizes', 'optimizer', and 'loss_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m search = run_random_search(Trainer_scratch(), param_dist_MLP, X_train, y_train, n_iter=\u001b[32m10\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Trainer.__init__() missing 4 required positional arguments: 'input_dim', 'hidden_sizes', 'optimizer', and 'loss_fn'"
     ]
    }
   ],
   "source": [
    "search = run_random_search(MLP, param_dist_MLP, X_train, y_train, n_iter=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to choose the best model from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will also have to run it on the whole dataset(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = best_model.predict(X_train)\n",
    "residual_plot(y_true=y_train, y_pred=y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_distribution(y_true=y_train, y_pred=y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parity_plot(y_pred=y_train_pred, y_true=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(best_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_plot(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_distribution(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parity_plot(y_pred=y_test_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, \"../models/best_mlp_scratch_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claims_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
